name: CI - KLDP Setup Validation

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

jobs:
  validate-setup:
    name: Validate KLDP Setup
    runs-on: ubuntu-latest
    timeout-minutes: 90

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Validate Python DAG syntax
        run: |
          echo "Installing Airflow for DAG validation..."
          pip install apache-airflow==3.1.0 \
            apache-airflow-providers-cncf-kubernetes \
            --constraint "https://raw.githubusercontent.com/apache/airflow/constraints-3.1.0/constraints-3.12.txt"

          echo "Validating DAG files..."
          for dag in examples/dags/*.py; do
            echo "Checking $dag..."
            python "$dag"
          done

      - name: Start Minikube
        uses: medyagh/setup-minikube@latest
        with:
          driver: docker
          container-runtime: containerd
          kubernetes-version: v1.28.3
          cpus: 2
          memory: 4000m
          wait: all
          start-args: '--delete-on-failure'

      - name: Verify Cluster
        run: |
          echo "=== Cluster info ==="
          kubectl cluster-info
          kubectl get nodes -o wide
          kubectl get pods -n kube-system

      - name: Set up Helm
        uses: azure/setup-helm@v4
        with:
          version: 'latest'

      - name: Create namespaces
        run: |
          kubectl create namespace airflow
          kubectl create namespace spark
          kubectl create namespace storage
          kubectl create namespace monitoring
          kubectl get namespaces


      - name: Add Airflow Helm repository
        run: |
          helm repo add apache-airflow https://airflow.apache.org
          helm repo update

      - name: Pre-pull Airflow images
        run: |
          echo "Pre-pulling images to avoid timeout during Helm install..."
          docker pull apache/airflow:3.1.0-python3.12
          docker pull postgres:13
          minikube image load apache/airflow:3.1.0-python3.12
          minikube image load postgres:13

      - name: Install Airflow
        run: |
          echo "Installing Airflow with KubernetesExecutor (CI-optimized with emptyDir)..."
          helm install airflow apache-airflow/airflow \
            --namespace airflow \
            --values core/airflow/values-ci-emptydir.yaml \
            --version 1.18.0 \
            --timeout 30m \
            --debug
        timeout-minutes: 35

      - name: Wait for Airflow pods
        run: |
          echo "Waiting for scheduler to be ready..."
          kubectl wait --for=condition=ready pod \
            -l component=scheduler \
            -n airflow \
            --timeout=600s

          echo "All Airflow components are ready!"
          kubectl get pods -n airflow

      - name: Copy and verify DAG
        run: |
          SCHEDULER_POD=$(kubectl get pods -n airflow -l component=scheduler -o jsonpath='{.items[0].metadata.name}')
          kubectl cp examples/dags/example_kubernetes_pod.py airflow/$SCHEDULER_POD:/opt/airflow/dags/
          sleep 30
          kubectl logs -n airflow $SCHEDULER_POD --tail=100 | grep -i "example_kubernetes_pod" || true

      - name: Install MinIO
        run: |
          echo "Installing MinIO object storage (CI-optimized)..."
          helm install minio oci://registry-1.docker.io/bitnamicharts/minio \
            --namespace storage \
            --values core/storage/minio-values-ci.yaml \
            --version 17.0.21 \
            --wait \
            --timeout 10m
        timeout-minutes: 15

      - name: Wait for MinIO pods
        run: |
          echo "Waiting for MinIO to be ready..."
          kubectl wait --for=condition=ready pod \
            -l app.kubernetes.io/name=minio \
            -n storage \
            --timeout=600s

          echo "MinIO is ready!"
          kubectl get pods -n storage

      - name: Install Spark Operator
        run: |
          echo "Installing Spark Operator..."
          helm repo add spark-operator https://kubeflow.github.io/spark-operator
          helm repo update

          helm install spark-operator spark-operator/spark-operator \
            --namespace spark \
            --values core/compute/spark-operator-values.yaml \
            --wait \
            --timeout 10m
        timeout-minutes: 15

      - name: Wait for Spark Operator pods
        run: |
          echo "Waiting for Spark Operator to be ready..."
          kubectl wait --for=condition=ready pod \
            -l app.kubernetes.io/name=spark-operator \
            -n spark \
            --timeout=300s

          echo "Spark Operator is ready!"
          kubectl get pods -n spark

      - name: Install Monitoring Stack
        run: |
          echo "Installing Prometheus/Grafana monitoring stack..."
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo update

          helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
            --namespace monitoring \
            --values core/monitoring/prometheus-grafana-values.yaml \
            --wait \
            --timeout 15m
        timeout-minutes: 20

      - name: Wait for Monitoring pods
        run: |
          echo "Waiting for Prometheus to be ready..."
          kubectl wait --for=condition=ready pod \
            -l app.kubernetes.io/name=prometheus \
            -n monitoring \
            --timeout=600s

          echo "Waiting for Grafana to be ready..."
          kubectl wait --for=condition=ready pod \
            -l app.kubernetes.io/name=grafana \
            -n monitoring \
            --timeout=600s

          echo "Monitoring stack is ready!"
          kubectl get pods -n monitoring

      - name: Verify all components
        run: |
          echo "=== Component Status ==="
          echo ""
          echo "Airflow:"
          kubectl get pods -n airflow
          echo ""
          echo "MinIO:"
          kubectl get pods -n storage
          echo ""
          echo "Spark Operator:"
          kubectl get pods -n spark
          echo ""
          echo "Monitoring:"
          kubectl get pods -n monitoring

      - name: Check Airflow logs
        if: always()
        run: |
          echo "=== API Server Logs ==="
          kubectl logs -n airflow -l component=api-server --tail=50 || true

          echo "=== Scheduler Logs ==="
          kubectl logs -n airflow -l component=scheduler --tail=50 || true

          echo "=== PostgreSQL Logs ==="
          kubectl logs -n airflow -l app.kubernetes.io/name=postgresql --tail=50 || true

      - name: Get all resources
        if: always()
        run: |
          echo "=== Airflow Pods ==="
          kubectl get pods -n airflow -o wide
          echo ""
          echo "=== MinIO Pods ==="
          kubectl get pods -n storage -o wide
          echo ""
          echo "=== Spark Pods ==="
          kubectl get pods -n spark -o wide
          echo ""
          echo "=== Monitoring Pods ==="
          kubectl get pods -n monitoring -o wide
          echo ""
          echo "=== All Services ==="
          kubectl get svc --all-namespaces
          echo ""
          echo "=== All PVCs ==="
          kubectl get pvc --all-namespaces
          echo ""
          echo "=== Airflow Events ==="
          kubectl get events -n airflow --sort-by='.lastTimestamp' | tail -20
          echo ""
          echo "=== Storage Events ==="
          kubectl get events -n storage --sort-by='.lastTimestamp' | tail -20
          echo ""
          echo "=== Spark Events ==="
          kubectl get events -n spark --sort-by='.lastTimestamp' | tail -20
          echo ""
          echo "=== Monitoring Events ==="
          kubectl get events -n monitoring --sort-by='.lastTimestamp' | tail -20

      - name: Describe failed pods
        if: failure()
        run: |
          echo "Describing any failed/pending pods in all namespaces..."

          for ns in airflow storage spark monitoring; do
            echo "=== Checking namespace: $ns ==="
            kubectl get pods -n $ns --field-selector=status.phase!=Running,status.phase!=Succeeded -o name | while read pod; do
              if [ -n "$pod" ]; then
                echo "=== Describing $pod in $ns ==="
                kubectl describe -n $ns $pod
              fi
            done
          done

  validate-scripts:
    name: Validate Shell Scripts
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install ShellCheck
        run: |
          sudo apt-get update
          sudo apt-get install -y shellcheck

      - name: Validate shell scripts
        run: |
          echo "Running ShellCheck on all shell scripts..."
          find scripts -name "*.sh" -type f -exec shellcheck {} \;
          echo "All scripts passed ShellCheck!"

      - name: Check script permissions
        run: |
          echo "Checking that scripts are executable..."
          for script in scripts/*.sh; do
            if [ -f "$script" ]; then
              if [ ! -x "$script" ]; then
                echo "Warning: $script is not executable"
                chmod +x "$script"
              fi
            fi
          done
          echo "Script permissions verified!"

  validate-yaml:
    name: Validate YAML Files
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install yamllint
        run: |
          pip install yamllint

      - name: Validate YAML syntax
        run: |
          echo "Validating YAML files..."
          find . -name "*.yaml" -o -name "*.yml" | grep -v ".github" | while read file; do
            echo "Checking $file..."
            yamllint -d relaxed "$file"
          done
          echo "All YAML files are valid!"

      - name: Validate Helm values
        run: |
          echo "Validating Helm values files..."
          python -c "
          import yaml
          import sys

          with open('core/airflow/values.yaml', 'r') as f:
              values = yaml.safe_load(f)

          # Basic validation checks
          assert values.get('executor') == 'KubernetesExecutor', 'Executor must be KubernetesExecutor'
          assert values.get('postgresql', {}).get('enabled') == True, 'PostgreSQL must be enabled'
          assert values.get('redis', {}).get('enabled') == False, 'Redis must be disabled for KubernetesExecutor'

          print('Helm values validation passed!')
          "
